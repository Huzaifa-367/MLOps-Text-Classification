{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# MLOps Assignment 1\n",
        "# Text Classification - **Testing**"
      ],
      "metadata": {
        "id": "ESalim4K5NpR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Deployment"
      ],
      "metadata": {
        "id": "Y_wbWR1B5T2l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load the saved model"
      ],
      "metadata": {
        "id": "CeCM6bio5Vhd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "# Define the file path where the trained model is saved\n",
        "model_file_path = \"naive_bayes_emotion_model.pkl\"\n",
        "\n",
        "# Load the saved Naive Bayes model from the file\n",
        "with open(model_file_path, 'rb') as file:\n",
        "    loaded_model = pickle.load(file)\n",
        "\n",
        "print(\"Trained model loaded successfully\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EqVXI3WV5Rpk",
        "outputId": "0a58d434-88c6-4acb-e356-6dfd37ae8063"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trained model loaded successfully\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Functions to Preprocess Text"
      ],
      "metadata": {
        "id": "9EQ18JC75e_-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MkzbBjSP5bu9",
        "outputId": "9eb0d3c0-fd89-4737-d0ef-b5ce632db6ca"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "import re\n",
        "import string\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import torch\n",
        "from transformers import AutoTokenizer\n",
        "import pickle\n",
        "\n",
        "# Download NLTK resources\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "# Function to remove punctuations from text\n",
        "def remove_punctuation(text):\n",
        "    regular_punct = string.punctuation\n",
        "    return str(re.sub(r'['+regular_punct+']', '', str(text)))\n",
        "\n",
        "# Function to remove URLs from text\n",
        "def remove_urls(text):\n",
        "    return re.sub(r'http[s]?://\\S+', '', text)\n",
        "\n",
        "# Function to convert the text into lower case\n",
        "def lower_case(text):\n",
        "    return text.lower()\n",
        "\n",
        "# Function to lemmatize text\n",
        "def lemmatize(text):\n",
        "    wordnet_lemmatizer = WordNetLemmatizer()\n",
        "    tokens = nltk.word_tokenize(text)\n",
        "    lemma_txt = ''\n",
        "    for w in tokens:\n",
        "        lemma_txt = lemma_txt + wordnet_lemmatizer.lemmatize(w) + ' '\n",
        "    return lemma_txt\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LS2NT74z5grW",
        "outputId": "ef0c12d7-c125-4d9f-f005-08a02a1bf98a"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Function to Predict Class"
      ],
      "metadata": {
        "id": "pCTzwvh25oAh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Function to preprocess text\n",
        "def preprocess_text(text):\n",
        "    text = remove_urls(text)\n",
        "    text = remove_punctuation(text)\n",
        "    text = lower_case(text)\n",
        "    text = lemmatize(text)\n",
        "    return text\n",
        "\n",
        "# Function to predict class\n",
        "def predict_class(input_text, model):\n",
        "    # Preprocess input text\n",
        "    input_text = preprocess_text(input_text)\n",
        "\n",
        "    # Tokenize the text\n",
        "    tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")\n",
        "    tokenized_text = tokenizer(input_text, return_tensors='pt', padding=True, truncation=True)\n",
        "\n",
        "    # Convert tokenized data into tensors\n",
        "    input_ids = tokenized_text['input_ids']\n",
        "    attention_mask = tokenized_text['attention_mask']\n",
        "\n",
        "    # Get the tokens\n",
        "    tokens = tokenizer.convert_ids_to_tokens(input_ids.flatten())\n",
        "\n",
        "    # Calculate the number of tokens\n",
        "    num_tokens = len(tokens)\n",
        "\n",
        "    # Here you can truncate or pad the number of tokens to match the expected number of features for MultinomialNB\n",
        "    # For example, you can truncate or pad to 94 tokens\n",
        "\n",
        "    # Truncate or pad the tokens to match the expected number of features\n",
        "    max_features = 94\n",
        "    if num_tokens > max_features:\n",
        "        # Truncate tokens\n",
        "        input_ids = input_ids[:, :max_features]\n",
        "        attention_mask = attention_mask[:, :max_features]\n",
        "    elif num_tokens < max_features:\n",
        "        # Pad tokens\n",
        "        input_ids = torch.nn.functional.pad(input_ids, (0, max_features - num_tokens), value=tokenizer.pad_token_id)\n",
        "        attention_mask = torch.nn.functional.pad(attention_mask, (0, max_features - num_tokens), value=0)\n",
        "\n",
        "    data = {'input_ids': input_ids, 'attention_mask': attention_mask}\n",
        "    data_tensors = {key: torch.tensor(val) for key, val in data.items()}\n",
        "\n",
        "    # Convert input_ids to NumPy array\n",
        "    input_ids_numpy = data_tensors['input_ids'].numpy()\n",
        "\n",
        "    # Reshape input_ids if necessary (optional step)\n",
        "    # input_ids_numpy = input_ids_numpy.reshape(input_ids_numpy.shape[0], -1)\n",
        "\n",
        "    # Make predictions using the model\n",
        "    predicted_class = model.predict(input_ids_numpy)\n",
        "    return predicted_class"
      ],
      "metadata": {
        "id": "GqhMIrK75ifV"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Testing"
      ],
      "metadata": {
        "id": "hePsic-F5tnH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define labels corresponding to the predicted classes\n",
        "labels = {0: \"sadness\", 1: \"joy\", 2: \"love\", 3: \"anger\", 4: \"fear\", 5: \"surprise\",}\n",
        "\n",
        "# List of input texts\n",
        "input_texts = [\n",
        "    \"im grabbing a minute to post i feel greedy wrong\",\n",
        "    \"this movie is amazing, I loved every minute of it\",\n",
        "    \"I'm not sure how I feel about this book, it's quite confusing\",\n",
        "    \"feeling happy and excited about the upcoming trip\",\n",
        "    \"today's weather is gloomy, it's making me sad\",\n",
        "    \"the food at that restaurant was terrible, I won't be going back\",\n",
        "]\n",
        "\n",
        "# Predict class for each input text\n",
        "for text in input_texts:\n",
        "    predicted_class = predict_class(text, loaded_model)\n",
        "    predicted_label = labels[int(predicted_class)]  # Get the corresponding label\n",
        "\n",
        "    print(f\"Input text: {text}\")\n",
        "    print(f\"Predicted class: {predicted_class} ({predicted_label})\")\n",
        "    print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hb7WFKER5mjs",
        "outputId": "44fc0808-5462-4f53-bb4f-bea238252b8f"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-49-38b91a384d1d>:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  data_tensors = {key: torch.tensor(val) for key, val in data.items()}\n",
            "<ipython-input-56-eff9077684c5>:17: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  predicted_label = labels[int(predicted_class)]  # Get the corresponding label\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input text: im grabbing a minute to post i feel greedy wrong\n",
            "Predicted class: [4] (fear)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-49-38b91a384d1d>:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  data_tensors = {key: torch.tensor(val) for key, val in data.items()}\n",
            "<ipython-input-56-eff9077684c5>:17: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  predicted_label = labels[int(predicted_class)]  # Get the corresponding label\n",
            "<ipython-input-49-38b91a384d1d>:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  data_tensors = {key: torch.tensor(val) for key, val in data.items()}\n",
            "<ipython-input-56-eff9077684c5>:17: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  predicted_label = labels[int(predicted_class)]  # Get the corresponding label\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input text: this movie is amazing, I loved every minute of it\n",
            "Predicted class: [0] (sadness)\n",
            "\n",
            "Input text: I'm not sure how I feel about this book, it's quite confusing\n",
            "Predicted class: [4] (fear)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-49-38b91a384d1d>:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  data_tensors = {key: torch.tensor(val) for key, val in data.items()}\n",
            "<ipython-input-56-eff9077684c5>:17: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  predicted_label = labels[int(predicted_class)]  # Get the corresponding label\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input text: feeling happy and excited about the upcoming trip\n",
            "Predicted class: [4] (fear)\n",
            "\n",
            "Input text: today's weather is gloomy, it's making me sad\n",
            "Predicted class: [4] (fear)\n",
            "\n",
            "Input text: the food at that restaurant was terrible, I won't be going back\n",
            "Predicted class: [0] (sadness)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-49-38b91a384d1d>:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  data_tensors = {key: torch.tensor(val) for key, val in data.items()}\n",
            "<ipython-input-56-eff9077684c5>:17: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  predicted_label = labels[int(predicted_class)]  # Get the corresponding label\n",
            "<ipython-input-49-38b91a384d1d>:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  data_tensors = {key: torch.tensor(val) for key, val in data.items()}\n",
            "<ipython-input-56-eff9077684c5>:17: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  predicted_label = labels[int(predicted_class)]  # Get the corresponding label\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SZmLkaziCdCc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}